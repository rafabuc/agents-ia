# â“ Preguntas Frecuentes (FAQ)

Respuestas a las preguntas mÃ¡s comunes sobre English Educator Agent.

---

## ğŸ“‹ Ãndice

- [General](#general)
- [InstalaciÃ³n y Setup](#instalaciÃ³n-y-setup)
- [Uso del Sistema](#uso-del-sistema)
- [Desarrollo](#desarrollo)
- [API y IntegraciÃ³n](#api-y-integraciÃ³n)
- [Deployment](#deployment)
- [Troubleshooting](#troubleshooting)

---

## ğŸŒ General

### Â¿QuÃ© es English Educator Agent?

English Educator Agent es un sistema multi-agente de IA diseÃ±ado para enseÃ±anza personalizada de inglÃ©s. Utiliza 6 agentes especializados que trabajan en conjunto para proporcionar evaluaciÃ³n de nivel, lecciones personalizadas, prÃ¡ctica conversacional, correcciÃ³n gramatical y seguimiento de progreso.

### Â¿QuÃ© tecnologÃ­as utiliza?

- **Backend**: Python 3.11, FastAPI
- **Frameworks IA**: LangChain, LangGraph
- **LLMs**: OpenAI GPT-4, Anthropic Claude
- **Base de Datos**: PostgreSQL, Qdrant (vector DB), Redis
- **MensajerÃ­a**: RabbitMQ, Celery
- **Monitoring**: Prometheus, Grafana, LangSmith

### Â¿Es cÃ³digo abierto?

SÃ­, el proyecto estÃ¡ bajo licencia MIT. Puedes usar, modificar y distribuir el cÃ³digo libremente.

### Â¿CuÃ¡nto cuesta ejecutar el sistema?

**Desarrollo local**: Gratis (excepto API calls a LLMs)

**ProducciÃ³n mensual estimado**:
- Infrastructure: $200-500
- LLM API calls: $500-2,000
- Total: ~$700-2,500 (depende del volumen)

---

## ğŸ”§ InstalaciÃ³n y Setup

### Â¿QuÃ© necesito para empezar?

**Software:**
- Python 3.10+
- Docker Desktop
- Git

**API Keys:**
- OpenAI API key
- Anthropic API key (opcional)
- LangSmith API key (opcional para tracing)

### Â¿CÃ³mo obtengo las API keys?

**OpenAI:**
1. Visita https://platform.openai.com
2. Crea cuenta/inicia sesiÃ³n
3. Ve a API keys y crea una nueva
4. Copia y guarda en `.env`

**Anthropic:**
1. Visita https://console.anthropic.com
2. Crea cuenta
3. Genera API key
4. Guarda en `.env`

### Â¿Funciona en Windows/Mac/Linux?

SÃ­, el sistema es compatible con:
- âœ… Windows 10/11
- âœ… macOS (Intel y Apple Silicon)
- âœ… Linux (Ubuntu, Debian, etc.)

### Â¿Puedo usar solo OpenAI o solo Anthropic?

SÃ­. El sistema estÃ¡ configurado para usar ambos, pero puedes:
- Solo OpenAI: Funciona completamente
- Solo Anthropic: Funciona completamente
- Ambos: Mejor experiencia (recomendado)

### El setup demora mucho, Â¿es normal?

SÃ­, la primera vez puede tomar 10-15 minutos:
- Docker descarga imÃ¡genes (~5 min)
- Python instala dependencias (~3 min)
- InicializaciÃ³n de servicios (~2 min)

---

## ğŸ’» Uso del Sistema

### Â¿CÃ³mo evalÃºo el nivel de un estudiante?

```bash
curl -X POST http://localhost:8000/api/v1/evaluate \
  -H "Content-Type: application/json" \
  -d '{"user_id": 1, "initial_message": "Hello"}'
```

O usa el endpoint WebSocket para evaluaciÃ³n interactiva.

### Â¿Puedo personalizar las lecciones?

SÃ­, puedes:
1. Modificar prompts en `backend/utils/prompts.py`
2. Agregar contenido educativo en `data/english_content/`
3. Ajustar parÃ¡metros del agente tutor

### Â¿CuÃ¡ntos estudiantes puede manejar simultÃ¡neamente?

**Desarrollo**: 10-20 usuarios concurrentes
**ProducciÃ³n** (con scaling): 1,000+ usuarios concurrentes

Depende de la infraestructura y configuraciÃ³n.

### Â¿El sistema soporta otros idiomas?

Actualmente estÃ¡ diseÃ±ado para enseÃ±ar inglÃ©s. Para otros idiomas:
- Modificar contenido educativo
- Ajustar prompts de agentes
- Actualizar evaluaciones CEFR

---

## ğŸ‘¨â€ğŸ’» Desarrollo

### Â¿CÃ³mo agrego un nuevo agente?

1. Crear archivo en `backend/agents/nuevo_agente.py`
2. Implementar clase heredando de estructura base
3. Registrar en supervisor (`backend/graphs/supervisor.py`)
4. Agregar tests en `tests/unit/`
5. Actualizar documentaciÃ³n

### Â¿CÃ³mo funciona el sistema RAG?

1. Contenido educativo se vectoriza con OpenAI embeddings
2. Se almacena en Qdrant (vector database)
3. Queries buscan contenido similar semÃ¡nticamente
4. Resultados se re-rankean con LLM
5. Contenido relevante se usa para generar respuestas

### Â¿Puedo cambiar el modelo de LLM?

SÃ­, edita `backend/config.py`:

```python
DEFAULT_GPT_MODEL = "gpt-4o"  # Cambiar a "gpt-4-turbo", "gpt-3.5-turbo", etc.
DEFAULT_CLAUDE_MODEL = "claude-3-5-sonnet-20241022"  # Cambiar versiÃ³n
```

### Â¿CÃ³mo debuggeo los agentes?

1. **LangSmith**: Tracing automÃ¡tico si configurado
2. **Logs**: Ver terminal donde corre uvicorn
3. **Debugger**: Usa VS Code o PyCharm debugger
4. **Print debugging**: Agregar `logger.info()` o `print()`

### Â¿DÃ³nde estÃ¡n los tests?

```
tests/
â”œâ”€â”€ unit/           # Tests unitarios de agentes
â”œâ”€â”€ integration/    # Tests de API y workflows
â””â”€â”€ e2e/           # Tests end-to-end
```

Ejecutar: `pytest tests/ -v`

---

## ğŸ”Œ API y IntegraciÃ³n

### Â¿Tiene documentaciÃ³n de API?

SÃ­, cuando el sistema estÃ¡ corriendo:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **Ejemplos**: Ver `API_EXAMPLES.md`

### Â¿Soporta WebSockets?

SÃ­, para chat en tiempo real:
- Chat: `ws://localhost:8000/ws/chat/{user_id}`
- EvaluaciÃ³n: `ws://localhost:8000/ws/evaluation/{user_id}`

### Â¿Hay rate limiting?

Configurado en `backend/config.py`:
```python
RATE_LIMIT_PER_MINUTE = 60  # requests por minuto
```

### Â¿CÃ³mo integro con mi aplicaciÃ³n?

1. **REST API**: Consume endpoints HTTP estÃ¡ndar
2. **WebSocket**: Para features en tiempo real
3. **SDK**: (futuro) Cliente Python/JavaScript

### Â¿Puedo usar solo la API sin frontend?

SÃ­, la API es independiente. Puedes:
- Usar solo backend
- Construir tu propio frontend
- Integrar con aplicaciones existentes

---

## ğŸš€ Deployment

### Â¿CÃ³mo despliego en producciÃ³n?

Ver `DEPLOYMENT_CHECKLIST.md` para guÃ­a completa.

Opciones:
1. **Docker Compose**: Para servidores simples
2. **Kubernetes**: Para producciÃ³n escalable
3. **Cloud managed**: AWS ECS, GCP Cloud Run, Azure Container Apps

### Â¿QuÃ© servicios cloud recomiendan?

**Recomendados:**
- **AWS**: EKS (Kubernetes), RDS (PostgreSQL), ElastiCache (Redis)
- **GCP**: GKE, Cloud SQL, Memorystore
- **Azure**: AKS, Azure Database, Azure Cache

### Â¿Necesito Kubernetes?

No es obligatorio:
- **Desarrollo**: Docker Compose suficiente
- **ProducciÃ³n pequeÃ±a**: Docker Compose + servidor
- **ProducciÃ³n grande**: Kubernetes recomendado

### Â¿CÃ³mo escalo el sistema?

**Horizontal scaling:**
1. Aumentar rÃ©plicas de backend
2. Agregar workers de Celery
3. Usar load balancer

**Vertical scaling:**
1. Aumentar recursos de containers
2. Optimizar queries de DB
3. Implementar caching agresivo

### Â¿CÃ³mo hago backups?

**Base de Datos:**
```bash
# PostgreSQL
pg_dump english_tutor > backup.sql

# Automatizar con cron
0 2 * * * pg_dump english_tutor > /backups/daily.sql
```

**Vector DB (Qdrant):**
- Usar snapshots de Qdrant
- Backup de volumen Docker
- Re-ingestar contenido si es necesario

---

## ğŸ” Troubleshooting

### Error: "Module not found"

```bash
# Asegurar que estÃ¡s en el venv
source venv/bin/activate

# Reinstalar dependencias
pip install -r requirements.txt
```

### Error: "Connection refused" (PostgreSQL/Redis)

```bash
# Verificar servicios Docker
cd docker && docker-compose ps

# Reiniciar servicios
docker-compose restart postgres redis

# Ver logs
docker-compose logs postgres
```

### Los agentes no responden

**Posibles causas:**
1. API keys invÃ¡lidas o expiradas
2. LÃ­mite de rate de API alcanzado
3. Servicios Docker no corriendo
4. Error en configuraciÃ³n `.env`

**SoluciÃ³n:**
```bash
# Verificar .env
cat .env

# Verificar servicios
docker-compose ps

# Ver logs del backend
# (en terminal donde corre uvicorn)
```

### Error: "No module named 'langchain'"

EstÃ¡s ejecutando fuera del venv:

```bash
# Activar venv primero
cd backend
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Luego ejecutar
python main.py
```

### WebSocket se desconecta

**Causas comunes:**
1. Timeout de inactividad
2. Proxy/firewall bloqueando
3. Error en el agente (ver logs)

**SoluciÃ³n:**
- Implementar heartbeat/ping
- Aumentar timeout
- Revisar logs del servidor

### Qdrant no encuentra contenido

```bash
# Primero, ingestar contenido
cd backend
python -m rag.ingest

# Verificar colecciÃ³n
curl http://localhost:6333/collections/english_content
```

### Celery no procesa tareas

```bash
# Verificar RabbitMQ
docker-compose ps rabbitmq

# Ver logs de Celery
# (en terminal donde corre el worker)

# Reiniciar worker
# Ctrl+C y luego:
celery -A tasks worker --loglevel=info
```

### Error: "Port already in use"

```bash
# Windows: Ver quÃ© usa el puerto
netstat -ano | findstr :8000

# Linux/Mac:
lsof -i :8000

# Matar proceso o usar otro puerto
uvicorn main:app --port 8001
```

### Tests fallan

```bash
# Asegurar servicios Docker corriendo
docker-compose ps

# Verificar variables de entorno
cat .env

# Ejecutar tests especÃ­ficos
pytest tests/unit/test_evaluator_agent.py -v

# Ver output completo
pytest tests/ -vv -s
```

---

## ğŸ“Š Performance

### Â¿CuÃ¡l es la latencia esperada?

**TÃ­pico:**
- API REST: 100-500ms
- LLM calls: 1-5 segundos
- WebSocket chat: 2-8 segundos (dependiendo del agente)

### Â¿CÃ³mo reduzco costos de LLM?

1. **Caching**: Cachear respuestas comunes
2. **Modelos mÃ¡s baratos**: Usar GPT-3.5 donde sea posible
3. **Batch requests**: Agrupar llamadas
4. **Prompt optimization**: Reducir tokens en prompts
5. **Fallback**: Usar modelos locales para tareas simples

### Â¿Puedo usar modelos locales?

SÃ­, puedes integrar:
- **Llama 2/3**: Con Ollama o LlamaCPP
- **Mistral**: Via Ollama
- **Custom models**: Implementar wrapper

Editar `backend/agents/` para usar modelos locales.

---

## ğŸ” Seguridad

### Â¿CÃ³mo protejo las API keys?

1. **Nunca** commitear `.env` a git
2. Usar **secrets manager** en producciÃ³n
3. Rotar keys regularmente
4. Implementar **rate limiting**
5. Usar **HTTPS** en producciÃ³n

### Â¿El sistema es seguro para producciÃ³n?

**Implementado:**
- âœ… Input validation
- âœ… Error handling
- âœ… CORS configurado
- âœ… Environment variables

**Por implementar:**
- â³ Authentication (JWT)
- â³ Authorization (RBAC)
- â³ Encryption at rest
- â³ Security audit

### Â¿Hay autenticaciÃ³n?

Actualmente no. Para aÃ±adir:
1. Implementar JWT tokens
2. Agregar middleware de auth
3. Proteger endpoints sensibles

Ver `backend/api/middleware.py` para comenzar.

---

## ğŸ“ˆ Roadmap

### Â¿QuÃ© viene despuÃ©s?

**Q1 2025:**
- Frontend web completo
- Mobile app (React Native)
- Speech-to-text integration

**Q2 2025:**
- Gamification
- Social features
- Multi-language support

### Â¿Puedo sugerir features?

Â¡SÃ­! Abre un issue en GitHub con:
- DescripciÃ³n del feature
- Caso de uso
- Beneficio esperado

Ver `CONTRIBUTING.md` para detalles.

---

## ğŸ’¬ Soporte

### Â¿DÃ³nde obtengo ayuda?

1. **DocumentaciÃ³n**: Primero revisa docs completa
2. **GitHub Issues**: Para bugs y features
3. **Discord**: Para chat en tiempo real
4. **Email**: support@english-tutor-ai.com

### Â¿Hay comunidad?

- **GitHub Discussions**: Para Q&A
- **Discord Server**: Para chat
- **Twitter**: @EnglishTutorAI
- **Blog**: blog.english-tutor-ai.com

### Â¿Ofrecen consultorÃ­a?

Para deployment enterprise o customizaciÃ³n:
- Email: enterprise@english-tutor-ai.com
- ConsultorÃ­a disponible
- Custom development
- Training y soporte

---

## ğŸ“ Aprendizaje

### Â¿Hay tutoriales?

SÃ­:
- `SETUP_GUIDE.md`: Setup paso a paso
- `API_EXAMPLES.md`: Ejemplos de API
- `PROGRAMA_COMPLETO_AGENTES_IA.md`: Curso completo

### Â¿DÃ³nde aprendo sobre agentes de IA?

Recursos recomendados:
1. **Nuestro curso**: `PROGRAMA_COMPLETO_AGENTES_IA.md`
2. **LangChain docs**: https://python.langchain.com
3. **LangGraph docs**: https://langchain-ai.github.io/langgraph/
4. **DeepLearning.AI**: Cursos de agentes

### Â¿Puedo usar esto para aprender?

Â¡Absolutamente! El proyecto es:
- CÃ³digo bien documentado
- Arquitectura clara
- Tests comprensivos
- Multiple use cases

Ideal para aprender sobre:
- Multi-agent systems
- LangChain/LangGraph
- RAG implementation
- Production LLM apps

---

## ğŸ“ Licencia y Legal

### Â¿Puedo usar esto comercialmente?

SÃ­, bajo licencia MIT puedes:
- âœ… Usar comercialmente
- âœ… Modificar
- âœ… Distribuir
- âœ… Uso privado

Requisitos:
- Incluir aviso de copyright
- Incluir licencia MIT

### Â¿Tengo que compartir mis cambios?

No es obligatorio. MIT permite:
- CÃ³digo privado
- Modificaciones propietarias
- No requirement de contribuir cambios

Pero contribuciones son Â¡bienvenidas! ğŸ‰

---

## â“ Otras Preguntas

### No encontrÃ© mi pregunta

1. Busca en **GitHub Issues** (open y closed)
2. Pregunta en **Discord**
3. Abre un **nuevo issue** con tag "question"

### Â¿CÃ³mo reporto un bug?

Ver `CONTRIBUTING.md` secciÃ³n "Reportar Bugs"

Template de bug report en GitHub Issues.

### Â¿Puedo contribuir?

Â¡SÃ­! Ver `CONTRIBUTING.md` para:
- GuÃ­as de contribuciÃ³n
- Code style
- Pull request process

---

**Â¿Tienes mÃ¡s preguntas?**

ğŸ‘‰ [Abrir un Issue](https://github.com/REPO/issues/new)
ğŸ‘‰ [Ãšnete a Discord](https://discord.gg/INVITE)
ğŸ‘‰ [Email](mailto:support@english-tutor-ai.com)

---

*Ãšltima actualizaciÃ³n: 2024*
*FAQ en constante actualizaciÃ³n basado en preguntas de la comunidad*
