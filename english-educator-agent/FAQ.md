# ‚ùì Preguntas Frecuentes (FAQ)

Respuestas a las preguntas m√°s comunes sobre English Educator Agent.

---

## üìã √çndice

- [General](#general)
- [Instalaci√≥n y Setup](#instalaci√≥n-y-setup)
- [Uso del Sistema](#uso-del-sistema)
- [Desarrollo](#desarrollo)
- [API y Integraci√≥n](#api-y-integraci√≥n)
- [Deployment](#deployment)
- [Troubleshooting](#troubleshooting)

---

## üåç General

### ¬øQu√© es English Educator Agent?

English Educator Agent es un sistema multi-agente de IA dise√±ado para ense√±anza personalizada de ingl√©s. Utiliza 6 agentes especializados que trabajan en conjunto para proporcionar evaluaci√≥n de nivel, lecciones personalizadas, pr√°ctica conversacional, correcci√≥n gramatical y seguimiento de progreso.

### ¬øQu√© tecnolog√≠as utiliza?

- **Backend**: Python 3.11, FastAPI
- **Frameworks IA**: LangChain, LangGraph
- **LLMs**: OpenAI GPT-4, Anthropic Claude
- **Base de Datos**: PostgreSQL, Qdrant (vector DB), Redis
- **Mensajer√≠a**: RabbitMQ, Celery
- **Monitoring**: Prometheus, Grafana, LangSmith

### ¬øEs c√≥digo abierto?

S√≠, el proyecto est√° bajo licencia MIT. Puedes usar, modificar y distribuir el c√≥digo libremente.

### ¬øCu√°nto cuesta ejecutar el sistema?

**Desarrollo local**: Gratis (excepto API calls a LLMs)

**Producci√≥n mensual estimado**:
- Infrastructure: $200-500
- LLM API calls: $500-2,000
- Total: ~$700-2,500 (depende del volumen)

---

## üîß Instalaci√≥n y Setup

### ¬øQu√© necesito para empezar?

**Software:**
- Python 3.10+
- Docker Desktop
- Git

**API Keys:**
- OpenAI API key
- Anthropic API key (opcional)
- LangSmith API key (opcional para tracing)

### ¬øC√≥mo obtengo las API keys?

**OpenAI:**
1. Visita https://platform.openai.com
2. Crea cuenta/inicia sesi√≥n
3. Ve a API keys y crea una nueva
4. Copia y guarda en `.env`

**Anthropic:**
1. Visita https://console.anthropic.com
2. Crea cuenta
3. Genera API key
4. Guarda en `.env`

### ¬øFunciona en Windows/Mac/Linux?

S√≠, el sistema es compatible con:
- ‚úÖ Windows 10/11
- ‚úÖ macOS (Intel y Apple Silicon)
- ‚úÖ Linux (Ubuntu, Debian, etc.)

### ¬øPuedo usar solo OpenAI o solo Anthropic?

S√≠. El sistema est√° configurado para usar ambos, pero puedes:
- Solo OpenAI: Funciona completamente
- Solo Anthropic: Funciona completamente
- Ambos: Mejor experiencia (recomendado)

### El setup demora mucho, ¬øes normal?

S√≠, la primera vez puede tomar 10-15 minutos:
- Docker descarga im√°genes (~5 min)
- Python instala dependencias (~3 min)
- Inicializaci√≥n de servicios (~2 min)

---

## üíª Uso del Sistema

### ¬øC√≥mo eval√∫o el nivel de un estudiante?

```bash
curl -X POST http://localhost:8000/api/v1/evaluate \
  -H "Content-Type: application/json" \
  -d '{"user_id": 1, "initial_message": "Hello"}'
```

O usa el endpoint WebSocket para evaluaci√≥n interactiva.

### ¬øPuedo personalizar las lecciones?

S√≠, puedes:
1. Modificar prompts en `backend/utils/prompts.py`
2. Agregar contenido educativo en `data/english_content/`
3. Ajustar par√°metros del agente tutor

### ¬øCu√°ntos estudiantes puede manejar simult√°neamente?

**Desarrollo**: 10-20 usuarios concurrentes
**Producci√≥n** (con scaling): 1,000+ usuarios concurrentes

Depende de la infraestructura y configuraci√≥n.

### ¬øEl sistema soporta otros idiomas?

Actualmente est√° dise√±ado para ense√±ar ingl√©s. Para otros idiomas:
- Modificar contenido educativo
- Ajustar prompts de agentes
- Actualizar evaluaciones CEFR

---

## üë®‚Äçüíª Desarrollo

### ¬øC√≥mo agrego un nuevo agente?

1. Crear archivo en `backend/agents/nuevo_agente.py`
2. Implementar clase heredando de estructura base
3. Registrar en supervisor (`backend/graphs/supervisor.py`)
4. Agregar tests en `tests/unit/`
5. Actualizar documentaci√≥n

### ¬øC√≥mo funciona el sistema RAG?

1. Contenido educativo se vectoriza con OpenAI embeddings
2. Se almacena en Qdrant (vector database)
3. Queries buscan contenido similar sem√°nticamente
4. Resultados se re-rankean con LLM
5. Contenido relevante se usa para generar respuestas

### ¬øPuedo cambiar el modelo de LLM?

S√≠, edita `backend/config.py`:

```python
DEFAULT_GPT_MODEL = "gpt-4o"  # Cambiar a "gpt-4-turbo", "gpt-3.5-turbo", etc.
DEFAULT_CLAUDE_MODEL = "claude-3-5-sonnet-20241022"  # Cambiar versi√≥n
```

### ¬øC√≥mo debuggeo los agentes?

1. **LangSmith**: Tracing autom√°tico si configurado
2. **Logs**: Ver terminal donde corre uvicorn
3. **Debugger**: Usa VS Code o PyCharm debugger
4. **Print debugging**: Agregar `logger.info()` o `print()`

### ¬øD√≥nde est√°n los tests?

```
tests/
‚îú‚îÄ‚îÄ unit/           # Tests unitarios de agentes
‚îú‚îÄ‚îÄ integration/    # Tests de API y workflows
‚îî‚îÄ‚îÄ e2e/           # Tests end-to-end
```

Ejecutar: `pytest tests/ -v`

---

## üîå API y Integraci√≥n

### ¬øTiene documentaci√≥n de API?

S√≠, cuando el sistema est√° corriendo:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **Ejemplos**: Ver `API_EXAMPLES.md`

### ¬øSoporta WebSockets?

S√≠, para chat en tiempo real:
- Chat: `ws://localhost:8000/ws/chat/{user_id}`
- Evaluaci√≥n: `ws://localhost:8000/ws/evaluation/{user_id}`

### ¬øHay rate limiting?

Configurado en `backend/config.py`:
```python
RATE_LIMIT_PER_MINUTE = 60  # requests por minuto
```

### ¬øC√≥mo integro con mi aplicaci√≥n?

1. **REST API**: Consume endpoints HTTP est√°ndar
2. **WebSocket**: Para features en tiempo real
3. **SDK**: (futuro) Cliente Python/JavaScript

### ¬øPuedo usar solo la API sin frontend?

S√≠, la API es independiente. Puedes:
- Usar solo backend
- Construir tu propio frontend
- Integrar con aplicaciones existentes

---

## üöÄ Deployment

### ¬øC√≥mo despliego en producci√≥n?

Ver `DEPLOYMENT_CHECKLIST.md` para gu√≠a completa.

Opciones:
1. **Docker Compose**: Para servidores simples
2. **Kubernetes**: Para producci√≥n escalable
3. **Cloud managed**: AWS ECS, GCP Cloud Run, Azure Container Apps

### ¬øQu√© servicios cloud recomiendan?

**Recomendados:**
- **AWS**: EKS (Kubernetes), RDS (PostgreSQL), ElastiCache (Redis)
- **GCP**: GKE, Cloud SQL, Memorystore
- **Azure**: AKS, Azure Database, Azure Cache

### ¬øNecesito Kubernetes?

No es obligatorio:
- **Desarrollo**: Docker Compose suficiente
- **Producci√≥n peque√±a**: Docker Compose + servidor
- **Producci√≥n grande**: Kubernetes recomendado

### ¬øC√≥mo escalo el sistema?

**Horizontal scaling:**
1. Aumentar r√©plicas de backend
2. Agregar workers de Celery
3. Usar load balancer

**Vertical scaling:**
1. Aumentar recursos de containers
2. Optimizar queries de DB
3. Implementar caching agresivo

### ¬øC√≥mo hago backups?

**Base de Datos:**
```bash
# PostgreSQL
pg_dump english_tutor > backup.sql

# Automatizar con cron
0 2 * * * pg_dump english_tutor > /backups/daily.sql
```

**Vector DB (Qdrant):**
- Usar snapshots de Qdrant
- Backup de volumen Docker
- Re-ingestar contenido si es necesario

---

## üîç Troubleshooting

### Error: "Module not found"

```bash
# Asegurar que est√°s en el venv
source venv/bin/activate

# Reinstalar dependencias
pip install -r requirements.txt
```

### Error: "Connection refused" (PostgreSQL/Redis)

```bash
# Verificar servicios Docker
cd docker && docker-compose ps

# Reiniciar servicios
docker-compose restart postgres redis

# Ver logs
docker-compose logs postgres
```

### Los agentes no responden

**Posibles causas:**
1. API keys inv√°lidas o expiradas
2. L√≠mite de rate de API alcanzado
3. Servicios Docker no corriendo
4. Error en configuraci√≥n `.env`

**Soluci√≥n:**
```bash
# Verificar .env
cat .env

# Verificar servicios
docker-compose ps

# Ver logs del backend
# (en terminal donde corre uvicorn)
```

### Error: "No module named 'langchain'"

Est√°s ejecutando fuera del venv:

```bash
# Activar venv primero
cd backend
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Luego ejecutar
python main.py
```

### WebSocket se desconecta

**Causas comunes:**
1. Timeout de inactividad
2. Proxy/firewall bloqueando
3. Error en el agente (ver logs)

**Soluci√≥n:**
- Implementar heartbeat/ping
- Aumentar timeout
- Revisar logs del servidor

### Qdrant no encuentra contenido

```bash
# Primero, ingestar contenido
cd backend
python -m rag.ingest

# Verificar colecci√≥n
curl http://localhost:6333/collections/english_content
```

### Celery no procesa tareas

```bash
# Verificar RabbitMQ
docker-compose ps rabbitmq

# Ver logs de Celery
# (en terminal donde corre el worker)

# Reiniciar worker
# Ctrl+C y luego:
celery -A tasks worker --loglevel=info
```

### Error: "Port already in use"

```bash
# Windows: Ver qu√© usa el puerto
netstat -ano | findstr :8000

# Linux/Mac:
lsof -i :8000

# Matar proceso o usar otro puerto
uvicorn main:app --port 8001
```

### Tests fallan

```bash
# Asegurar servicios Docker corriendo
docker-compose ps

# Verificar variables de entorno
cat .env

# Ejecutar tests espec√≠ficos
pytest tests/unit/test_evaluator_agent.py -v

# Ver output completo
pytest tests/ -vv -s
```

---

## üìä Performance

### ¬øCu√°l es la latencia esperada?

**T√≠pico:**
- API REST: 100-500ms
- LLM calls: 1-5 segundos
- WebSocket chat: 2-8 segundos (dependiendo del agente)

### ¬øC√≥mo reduzco costos de LLM?

1. **Caching**: Cachear respuestas comunes
2. **Modelos m√°s baratos**: Usar GPT-3.5 donde sea posible
3. **Batch requests**: Agrupar llamadas
4. **Prompt optimization**: Reducir tokens en prompts
5. **Fallback**: Usar modelos locales para tareas simples

### ¬øPuedo usar modelos locales?

S√≠, puedes integrar:
- **Llama 2/3**: Con Ollama o LlamaCPP
- **Mistral**: Via Ollama
- **Custom models**: Implementar wrapper

Editar `backend/agents/` para usar modelos locales.

---

## üîê Seguridad

### ¬øC√≥mo protejo las API keys?

1. **Nunca** commitear `.env` a git
2. Usar **secrets manager** en producci√≥n
3. Rotar keys regularmente
4. Implementar **rate limiting**
5. Usar **HTTPS** en producci√≥n

### ¬øEl sistema es seguro para producci√≥n?

**Implementado:**
- ‚úÖ Input validation
- ‚úÖ Error handling
- ‚úÖ CORS configurado
- ‚úÖ Environment variables

**Por implementar:**
- ‚è≥ Authentication (JWT)
- ‚è≥ Authorization (RBAC)
- ‚è≥ Encryption at rest
- ‚è≥ Security audit

### ¬øHay autenticaci√≥n?

Actualmente no. Para a√±adir:
1. Implementar JWT tokens
2. Agregar middleware de auth
3. Proteger endpoints sensibles

Ver `backend/api/middleware.py` para comenzar.

---

## üìà Roadmap

### ¬øQu√© viene despu√©s?

**Q1 2025:**
- Frontend web completo
- Mobile app (React Native)
- Speech-to-text integration

**Q2 2025:**
- Gamification
- Social features
- Multi-language support

### ¬øPuedo sugerir features?

¬°S√≠! Abre un issue en GitHub con:
- Descripci√≥n del feature
- Caso de uso
- Beneficio esperado

Ver `CONTRIBUTING.md` para detalles.

---

## üí¨ Soporte

### ¬øD√≥nde obtengo ayuda?

1. **Documentaci√≥n**: Primero revisa docs completa
2. **GitHub Issues**: Para bugs y features
3. **Discord**: Para chat en tiempo real
4. **Email**: support@english-tutor-ai.com

### ¬øHay comunidad?

- **GitHub Discussions**: Para Q&A
- **Discord Server**: Para chat
- **Twitter**: @EnglishTutorAI
- **Blog**: blog.english-tutor-ai.com

### ¬øOfrecen consultor√≠a?

Para deployment enterprise o customizaci√≥n:
- Email: enterprise@english-tutor-ai.com
- Consultor√≠a disponible
- Custom development
- Training y soporte

---

## üéì Aprendizaje

### ¬øHay tutoriales?

S√≠:
- `SETUP_GUIDE.md`: Setup paso a paso
- `API_EXAMPLES.md`: Ejemplos de API
- `PROGRAMA_COMPLETO_AGENTES_IA.md`: Curso completo

### ¬øD√≥nde aprendo sobre agentes de IA?

Recursos recomendados:
1. **Nuestro curso**: `PROGRAMA_COMPLETO_AGENTES_IA.md`
2. **LangChain docs**: https://python.langchain.com
3. **LangGraph docs**: https://langchain-ai.github.io/langgraph/
4. **DeepLearning.AI**: Cursos de agentes

### ¬øPuedo usar esto para aprender?

¬°Absolutamente! El proyecto es:
- C√≥digo bien documentado
- Arquitectura clara
- Tests comprensivos
- Multiple use cases

Ideal para aprender sobre:
- Multi-agent systems
- LangChain/LangGraph
- RAG implementation
- Production LLM apps

---

## üìù Licencia y Legal

### ¬øPuedo usar esto comercialmente?

S√≠, bajo licencia MIT puedes:
- ‚úÖ Usar comercialmente
- ‚úÖ Modificar
- ‚úÖ Distribuir
- ‚úÖ Uso privado

Requisitos:
- Incluir aviso de copyright
- Incluir licencia MIT

### ¬øTengo que compartir mis cambios?

No es obligatorio. MIT permite:
- C√≥digo privado
- Modificaciones propietarias
- No requirement de contribuir cambios

Pero contribuciones son ¬°bienvenidas! üéâ

---

## ‚ùì Otras Preguntas

### No encontr√© mi pregunta

1. Busca en **GitHub Issues** (open y closed)
2. Pregunta en **Discord**
3. Abre un **nuevo issue** con tag "question"

### ¬øC√≥mo reporto un bug?

Ver `CONTRIBUTING.md` secci√≥n "Reportar Bugs"

Template de bug report en GitHub Issues.

### ¬øPuedo contribuir?

¬°S√≠! Ver `CONTRIBUTING.md` para:
- Gu√≠as de contribuci√≥n
- Code style
- Pull request process

---

**¬øTienes m√°s preguntas?**

üëâ [Abrir un Issue](https://github.com/REPO/issues/new)
üëâ [√önete a Discord](https://discord.gg/INVITE)
üëâ [Email](mailto:support@english-tutor-ai.com)

---

*√öltima actualizaci√≥n: 2024*
*FAQ en constante actualizaci√≥n basado en preguntas de la comunidad*
